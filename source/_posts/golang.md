---
title: 操作系统-磁盘内存管理
date: 2022-01-05 04:04:43
categories: 
 - 学习
---

cpu cache mesi

mysql 最左匹配原则

mutex rwlock 悲观锁 读多写少

cas  读多写少 无锁map 乐观锁 原子操作

map 线程安全

空结构体 不占内存

切片数组 值类型直接对应内存中的值 引用类型指向内存中存放该值的地址

gc 三色标记 stw 停止 sink 对象池



# tcp 查询状态 timewait closewait 
https://blog.csdn.net/Shuffle_Ts/article/details/93778635
https://blog.csdn.net/Shuffle_Ts/article/details/93909003

# 缓存一致性  https://www.cnblogs.com/xiaolincoding/p/16493675.html
1. 旁路缓存：先更新数据库再删除缓存，而不是更新缓存 lazy 用到在取 用到在初始化
2. 直写： 
3. 回写/写回：

# cpu cache 一致性 mesi https://www.cnblogs.com/xiaolincoding/p/13886559.html
以前100MHZ的cpu主频的时代，cpu直接从内存读取数据还是能接受的，后来CPU的频率太快了，快到主存跟不上，这样在处理器时钟周期内，CPU常常需要等待主存，这样就会浪费资源。

缓解CPU和内存之间速度的不匹配问题，出现cpu cache

解决cpu cache 与 memeory 保持数据一致，提出只写和回写

解决多核cpu里的cache 缓存一致性，提出mesi（modify exclusive shared invalidated）

# 垃圾回收 stw

程序运行时的内存空间（堆栈）

之所以要区分堆和栈，是由于程序需要两种不同特性的内存形似而确定的。在C++中，新建一个对象有两种方式，静态分配和动态分配。

**栈由系统进行管理，而堆由程序员自己管理**

静态分配（数组）已在代码中定义了大小，编译时完成内存空间的分配
 
一般来说，静态分配用于初始化已知对象大小的时候，比如int a[10];如果我们能够确定这个数组是10个，我们可以使用这种方式。这种方式所需要的内存在编译期间即可确定，因此操作系统便可以预先确定所指定大小内存给变量，并且可以在变量生命周期结束后自动释放。

动态分配(切片) 无法在编译时确定大小，需要动态分配内存空间

然而在某些场景下，可能需要根据某些情况来申请内存，比如int* a =new int[count];而变量count可能就来自于某个配置文件或者用户手动输入的值。这个时候操作系统就无法再预先确定内存大小，并且不执行到new int[count]这一行代码的时候，是无法知道所要分配的内存大小，因此操作系统分出一块内存，用来进行动态分配。并且规定，动态分配的内存需要由客户端自行管理。

STW(stop the world)，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，Golang进行了多次的迭代优化来解决这个问题。

1.3以前的版本使用标记-清扫的方式，整个过程都需要STW。
1.3版本分离了标记和清扫的操作，标记过程STW，清扫过程并发执行。
1.5版本在标记过程中使用三色标记法。回收过程主要有四个阶段，其中，标记和清扫都并发执行的，但标记阶段的前后需要STW一定时间来做GC的准备工作和栈的re-scan。

强弱三色不变式
从 root set 根节点集合 出发扫描栈空间的对象，及其被引用的对象， 扫描堆的对象，及其引用的对象  
栈内对象的操作无屏障技术
插入屏障 针对堆的扫描黑对白引用，白变灰，最后扫描栈stw
删除屏障 针对堆的扫描黑或灰删除任意引用，被删除的引用变灰，下一轮再回收，造成回收精度低
混合写屏障 扫描栈对象全部标为黑，新增的栈对象也为黑，堆中被删除的引用标为灰，被添加的引用标为灰

屏障

https://juejin.cn/post/7178777729028866104
https://blog.csdn.net/xia_2017/article/details/128834696

https://zhuanlan.zhihu.com/p/334999060
https://zhuanlan.zhihu.com/p/74853110#:~:text=%E5%9C%A8Golang%E4%B8%AD,%E8%BF%87%E7%A8%8B%E9%9C%80%E8%A6%81STW%E3%80%82

### gc 垃圾回收
#### v1.1 stw （ignore）

#### v1.3 标记时stw 清除时并发 

#### v1.5 三色+屏障技术(插入屏障，删除屏障)(强弱三色不变式) 达到 标记时并发 清除时并发 的效果 

可以看出，有两个问题, 在三色标记法中,是不希望被发生的

-  条件1: 一个白色对象被黑色对象引用(白色被挂在黑色下)
-  条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏(灰色同时丢了该白色)

当以上两个条件**同时满足**时, 就会出现对象丢失现象!


插入屏障(写屏障): 标记过程中 黑色引用白色， 白色变为灰色 。 成本高只在堆中使用，所以扫描结束后会再扫描一遍栈中对象，检查是否有新引用的白色对象。保护堆中黑色对象引用白色对象。


删除屏障： 标记过程中 白色或灰色对象 对白色对象的引用 被删除， 被删除的对象变为灰色。保护灰色对象到白色对象的路径不会断来实现的。 在这种实现方式中，回收器悲观的认为所有被删除的对象（白色对象）都可能会被黑色对象引用。

#### v1.8 三色+混合写屏障
1. 栈上对象全标为黑色（无须stw重新扫描）
2. 扫描过程中，栈上新创建的对象全部标为黑色
3. 扫描过程中，被删除引用的对象标为灰
4. 扫描过程中，被引用的对象标为灰

#### gc 触发时间

分为**系统触发**和**主动触发**。

空间不足 时间定时 手动

1）gcTriggerHeap：当所分配的堆大小达到阈值（由控制器计算的触发堆的大小）时，将会触发。

2）gcTriggerTime：当距离上一个 GC 周期的时间超过一定时间时，将会触发。时间周期以runtime.forcegcperiod 变量为准，默认 2 分钟。

3）gcTriggerCycle：如果没有开启 GC，则启动 GC。 给手动runtime.GC的接口，调用启动gc

4）通过手动触发的 runtime.GC 方法。

## GMP 调度模型 解决程序里产生的多线程如何调度执行的问题
https://blog.csdn.net/xmcy001122/article/details/119392934

全局队列

G goroutine  go func(){...} 包含了当前 goroutine 的状态、堆栈、上下文 轻量一般大小2kb 无数量大小限制。

P Processor 处理器不是真正cpu 默认数量为cpu核心数  连接GM的中间件 使G在M中执行 解决GM模型缺点引入的中间层 含有由G组成的本地队列，固定大小为256。 空则从其余P中work stealing或全局队列中取，满则减半到全局队列。    
所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。

调度器 shed

M machine 实际在内核中工作的线程 默认最大10000个，可在程序运行中创建和复用空闲。时分复用执行P的本地队列里的G, 当在执行中的G产生阻塞时，P带着本地队列其余的G转移到一个新建或空闲的M里继续执行其余G。 g的时间片10ms, 超过轮到下一个g。
需要绑定 P 才能进行具体的任务执行的。

总结，Go 调度器很轻量也很简单，足以撑起 goroutine 的调度工作，并且让 Go 具有了原生（强大）并发的能力。Go 调度本质是把大量的 goroutine 分配到少量线程上去执行，并利用多核并行，实现更强大的并发。

更多的可以看这几篇文章：再见 Go 面试官：[GMP 模型，为什么要有 P？]、Go 群友提问：[Goroutine 数量控制在多少合适，会影响 GC 和调度？]、[work-stealing scheduler]

### gmp 为什么要有P? https://juejin.cn/post/6968311281220583454 

我的理解：起到对G的缓存队列， 就如同数据库的缓存 让p管理g的执行, m空闲就从p中去取, 不到万不得已不用去全局g中去取，减少频繁切换导致的资源开销。

### goroutine切换(触发调度)的时机， 当 G 阻塞在M中时，会发生什么？

- https://blog.csdn.net/qq_37186127/article/details/125519834
我们需要知道在Go中代码的执行是需要线程（M）绑定 P 才能在CPU上执行

如果说我们线程在执行的时候阻塞了，那么程序是不是要无限创建线程才能执行？

在Go中，这种情况是不会阻塞调度的，而是会把goroutin挂起

所谓挂起，就是让G进入某个数据结构，待ready后再继续执行，不会占用线程

线程会进入schedule，继续消费队列，执行其它的G!


- https://www.cnblogs.com/CJ-cooper/p/15270475.html
work-stealing调度算法：当M执行完了当前P的本地队列队列里的所有G后，P也不会就这么在那躺尸啥都不干，它会先尝试从全局队列队列寻找G来执行，如果全局队列为空，它会随机挑选另外一个P，从它的队列里中拿走一半的G到自己的队列中执行。

如果一切正常，调度器会以上述的那种方式顺畅地运行，但这个世界没这么美好，总有意外发生，以下分析goroutine在两种例外情况下的行为。

Go runtime会在下面的goroutine被阻塞的情况下运行另外一个goroutine：

用户态阻塞/唤醒

当goroutine因为channel操作或者network I/O而阻塞时（实际上golang已经用netpoller实现了goroutine网络I/O阻塞不会导致M被阻塞，仅阻塞G，这里仅仅是举个栗子），对应的G会被放置到某个wait队列(如channel的waitq)，该G的状态由_Gruning变为_Gwaitting，而M会跳过该G尝试获取并执行下一个G，如果此时没有可运行的G供M运行，那么M将解绑P，并进入sleep状态；当阻塞的G被另一端的G2唤醒时（比如channel的可读/写通知），G被标记为，尝试加入G2所在P的runnext（runnext是线程下一个需要执行的 Goroutine。）， 然后再是P的本地队列和全局队列。

系统调用阻塞

当M执行某一个G时候如果发生了阻塞操作，M会阻塞，如果当前有一些G在执行，调度器会把这个线程M从P中摘除，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P。当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中。

### 当写下go func的时候，到底发生了什么？
https://blog.csdn.net/qq_37186127/article/details/125517300

## 0201 总结 todo

讲讲go的协程、协程与线程 https://blog.csdn.net/weixin_49199646/article/details/109210547 内核无法感知的用户态级别的线程，有程序自行创建，管理，销毁。

让你实现一个RPC框架，应该要考虑哪些点
grpc

go怎么做到面向对象

/*
如果延时topic里有一亿条消息，如何取出即将到延时时间的消息？全表扫描？
看你说服务QPS很高，对于高并发场景下有什么需要注意的问题
异步调用一定比同步调用快吗
100的QPS，同步调用开100个进程，是否比多线程（线程池）更优？
*/

四次挥手中TIME_WAITED等待2MSL的原因

一亿个文件，每个文件里有一亿个字符串，找出相同的字符串

# 0203 todo

阻塞IO和非阻塞IO有什么区别 

零拷贝： io时数据需要在内核态和用户态间的数据缓存区进行多次拷贝传输，造成频繁用户态和内核态的上下文切换和内存拷贝的次数，效率低下。 

如何实现多路复用IO
https://zhuanlan.zhihu.com/p/115220699
可以在单线程/进程中处理多个事件流(鼠标键盘 中断) 解决的本质问题是在用更少的资源完成更多的事。

select、epoll原理

Redis跳表如何实现？时间复杂度？
MySQL联合索引使用问题，覆盖索引相关。

arp表的作用？arp的分组格式？对于主机不存在的apr请求会发生什么？

DNS的作用？DNS的解析流程？

下一跳路由转发数据包的过程？

协程切换的时机？
若 主goroutine 比 子goroutine 先结束会有什么问题？ 

MySQL默认**事务隔离**级别

InnoDB索引的底层数据结构及其优点
b+树
层级浅，效率高
叶子节点使用链表连接，范围查询搞笑


# 0202 csp 实体goruntine 管道channel 通信 并发模型
https://zhuanlan.zhihu.com/p/313763247


CSP 是 Communicating Sequential Process 的简称，中文可以叫做通信顺序进程，是一种并发编程模型，用于描述两个独立的并发实体通过共享的通讯 channel(管道)进行通信的并发模型。**CSP中 channel 不关注发送消息的实体，而关注与发送消息时使用的channel。**

严格来说，CSP 是一门形式语言（类似于 ℷ calculus），用于描述并发系统中的互动模式，也因此成为一众面向并发的编程语言的理论源头

Golang，其实只用到了 CSP 的很小一部分，即理论中的 Process/Channel（对应到语言中的 goroutine/channel）：goroutine 是实际并发执行的实体，每个实体之间是通过channel通讯来实现数据共享, 形成一套有序阻塞和可预测的并发模型。

优点:
我的理解是这样的，对一个共享内存的对象，如果每个都要去修改的话，就必须得记得加锁和解锁，甚至更复杂的操作，而channel则是生产者和消费者，不需要关注锁和共享内存的复杂性，把共享内存看成一份输入和输出的数据

## channel的底层结构？接收、发送消息的过程？ channel底层

FIFO   CAS  

结构体 buf lock sendx recvx qcount dataqsiz elemsize elemtype closed 是否已经关闭
```
type hchan struct {
	qcount   uint           	//当前通道元素个数（len）
	dataqsiz uint           	//最大队列长度（cap）
	buf      unsafe.Pointer 	//队列指针，指向队列内存位置
	elemsize uint16				//单个元素大小
	elemtype *_type 			//元素类型
	closed   uint32				//标识通道状态
	sendx    uint   			//下一个发送的元素在buf中存放的位置
	recvx    uint   			//下一个接收的元素在buf中读取的位置
	recvq    waitq  			//等待读消息的协程队列
	sendq    waitq  			//等待发消息的协程队列
	lock mutex					//互斥锁，保证不存在并发读写管道
	//可以在GOROOT/src/runtime/chan.go里看到源码
}
```

```
其中 buf 是一个循环队列，用来存储 channel 接收的数据，lock 用来保护数据安全，goroutine 来访问 channel 的 buf 之前，需要先获取锁。
sendx 表示当前数据发送的的位置，recvx 表示当前数据接收的位置。sendq 和 recvq 是两个队列，这两个结构很重要，我们下面会讲到。
qcount 表示当前 buf 中存储的数据个数，dataqsiz 表示 buf 可以接受的最大数据数量。elemtype 就表示数据的类型。
channel 在使用 make 创建的时候，实际上会在堆上分配一块空间，初始化 hchan 结构，然后返回 hchan 的指针。这就是为什么在使用 channel 的时候，直接传递就可以，而不用获取 channel 的指针，这是因为 channel 本身就是指针。 
```
- 什么时候发生阻塞？
1. 向一个值为nil的管道写或读数据
2. 无缓冲区时单独的写或读数据
3. 缓冲区为空时进行读数据
4. 缓冲区满时进行写数据

- 阻塞的本质？（channel如何使goroutine进入阻塞状态）
非缓存通道：往管道 ch 发送数据 发送超过缓存区0， 将 go阻塞 并 其抽象记录为 sudog 放入 sendx 发送阻塞队列 中，直到 recvx 有其他 sudog 来获取数据

缓存通道：往管道 ch 发送数据 若发送超过缓存区大小， 将 go阻塞 并 其抽象记录为 sudog 放入 sendx 发送阻塞队列 中，直到有其他goroutine来读数据，释放缓存区, 解除阻塞状态。


## 0204 设计模式 todo

总共有 23 种设计模式。这些模式可以分为三大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns）

创建型模式
这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。

结构型模式
这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。

行为型模式
这些设计模式特别关注对象之间的通信。


### 单例模式 singleton
一个类实例一个对象，该对象在类中实例化后由类自己管理，只提供全局访问的接口方法，防止其他地方修改。

饿汉式 lazy ： 第一次访问使用才初始化， 避免资源浪费。确保线程安全，防止同时访问实例化产生多个对象。
单锁: 整个接口加锁
双重锁：接口不加锁， 对象为null，初始化才获取锁（该锁检查对象是否初始化），不用每次访问都要获取锁造成线程的阻塞。

使⽤场景总结：
1. 频繁实例化然后又销毁的对象，使用单例模式可以提高性能
2. 经常使用的对象，但实例化时耗费时间或者资源多，如数据库连接池，使用单例模式，可以提高性能，降低资源损坏
3. 使用线程池之类的控制资源时，使用单例模式，可以方便资源之间的通信

### 策略模式 stragety

对两个数xy进行运算，可以通过计算器中包含的加减乘除等多种运算策略，根据不同的运算策略来得到运算结果。

去某个地方，可以选择飞机、高铁、顺风车、自驾等方式。

定义一系列的算法，把它们单独封装起来，并且使它们可以互相替换，使得算法可以独立于使用它的客户端而变化，也是说**这些算法所完成的功能类型是一样的，对外接口也是一样的**，只是**不同的策略为引起环境角色表现出不同的行为**。

相比于使用大量的if...else，使用策略模式可以降低复杂度，使得代码更容易维护。缺点：可能需要定义大量的策略类，并且这些策略类都要提供给客户端。

优点：
使用策略模式可以避免使用多重条件转移语句。多重转移语句将算法或行为的逻辑混合在一起，不易维护

缺点：
客户端必须知道所有的策略类，并自行决定使用哪一个策略类，策略模式只适用于客户端知道所有的算法或行为的情况。


## 0205 
### http tcp keepalive 长连接 

https://zhuanlan.zhihu.com/p/224595048

#### http keepalive

无状态 HTTP协议永远都是客户端发起请求，服务器回送响应。每次连接只处理一个请求，当服务器返回本次请求的应答后便立即关闭连接。 不会记录http历史连接信息。

HTTP协议运行在TCP协议之上，它无状态会导致客户端的每次请求都需要重新建立TCP连接，接受到服务端响应后，断开TCP连接。对于每次建立、断开TCP连接，还是有相当的性能损耗的。

减少性能损耗: keep-alive 机制

http1.0默认关闭，开启参数 connection:keep-alive
http1.1默认开启，关闭参数 connection:close

keep-alive机制：若开启后，在一次http请求中，服务器进行响应后，**不再直接断开TCP连接**，而是将TCP连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起http请求，便可以复用此TCP连接，向服务端发起请求，并重置timeout时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁TCP连接的损耗。

#### tcp keepalive

tcp 三次握手建立连接，数据发送完成，连接进入不活跃状态，双方有一端开启保活功能，发送保活报文，另一端成功接收响应报文，重置保活时间计数器。若由于网络原因或其他原因导致，发送端无法正常收到保活探测报文的响应。再次发送直至达到探测循环次数都没有接收到对端响应，认为不可达，中断处理。
<!-- 
如果在一段时间（保活时间：tcp_keepalive_time）内此连接都不活跃，开启保活功能的一端会向对端发送一个保活探测报文。

若对端正常存活，且连接有效，对端必然能收到探测报文并进行响应。此时，发送端收到响应报文则证明TCP连接正常，重置保活时间计数器即可。

若由于网络原因或其他原因导致，发送端无法正常收到保活探测报文的响应。那么在一定探测时间间隔（tcp_keepalive_intvl）后，将继续发送保活探测报文。直到收到对端的响应，或者达到配置的探测循环次数上限（tcp_keepalive_probes）都没有收到对端响应，这时对端会被认为不可达，TCP连接随存在但已失效，需要将连接做中断处理。 -->


#### 回到文章开头提出的问题：HTTP和TCP的长连接有何区别？HTTP中的keep-alive和TCP中keepalive又有什么区别？

1、TCP连接往往就是我们广义理解上的长连接，因为它具备双端连续收发报文的能力；
开启了keep-alive的HTTP连接，也是一种长连接，但是它由于协议本身的限制，服务端无法主动发起应用报文。

2、TCP中的keepalive是用来保鲜、保活的；
HTTP中的keep-alive机制主要为了让支撑它的TCP连接活的的更久，所以通常又叫做：HTTP persistent connection（持久连接） 和 HTTP connection reuse（连接重用）。
-   

### websocket 传输过程

### 负载均衡算法 https://zhuanlan.zhihu.com/p/68733507
1、轮询法

将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。

2、随机法

通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，

其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。

3、源地址哈希法

源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。

4、加权轮询法

不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。

5、加权随机法

与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。

6、最小连接数法

最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前
积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。


### 缓存 https://zhuanlan.zhihu.com/p/346651831
缓存雪崩|大量keys
保存过期随机值，防止大量keys失效
熔断机制 禁止部分访问

缓存击穿|热点 
设置热点key永久保存
互斥锁 针对热点

缓存穿透|null
设置value为null的key
布隆过滤器 访问数据库前先查询，存在有可能误判才去查询，不存在一定不存在返回null

### websocket 过程 原理

1. 客户端发送 http header里包含 upgrade:websocket 请求  
2. 服务端接收返回 101状态码 表示同意升级
3. 连接复用此前http建立的tcp连接

WebSocket 实现了**双向通信**的技术了，迄今为止，大部分开发者还是使用 Ajax 轮询来实现，但这是个不太优雅的解决办法，WebSocket 虽然用的人不多，可能是因为协议刚出来的时候有安全性的问题以及兼容的浏览器比较少，但现在都有解决。如果你有这些需求可以考虑使用 WebSocket：

1 、多个用户之间进行交互；

2、需要频繁地向服务端请求更新数据。

比如弹幕、消息订阅、多玩家游戏、协同编辑、股票基金实时报价、视频会议、在线教育等需要高实时的场景。


## 0206

### 分库分表 todo

### cas 乐观锁 原子操作 实际无锁算法 compare and swap 比较并交换

atomic.CompareAndSwap

原子操作 要么完全不执行，要么全部执行完。

假定有两个操作A 和B，如果从执行A 的线程来看，当另一个线程执行B 时，要么将B 全部执行完，要么完全不执行B，那么A 和B 对彼此来说是原子的。

CAS是一种无锁算法，CAS有3个操作数，内存位置（V）、预期原值（A）和新值(B)。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则不会进行修改。

如何确保线程安全？
启动10个线程循环自增i的值10次，让 i:=1 循环自增到100 

1. 与原值不匹配 循环
a、b线程同时 读取i=1, 修改后a比b先修改完成，此时i被a修改为2。此时，b线程修改i时发现i=2,放弃修改，并进入循环此前操作（获取i进行自增操作），直到i符合预期值才完成修改。

2. 或者原值修改aba
加入版本号或时间戳，符合预期再更新

### sync mutex todo

mutex rwmutex waitgroup atomic cas map pool once  

### 项目：  分布式面试 
grpc 定义传输格式： .protobuf文件 生成 .go文件 里面定义了数据格式的结构体，以及序列化和反序列化的方法


### golang context 上下文
https://www.cnblogs.com/juanmaofeifei/p/14439957.html

### 微服务
https://github.com/rubyhan1314/Golang-100-Days/blob/master/Day76(%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%89%B9%E6%80%A7)/day76_%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B%E5%8F%8A%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D.md

将传统的单体项目系统，按项目的架构层次拆解成多个微服务(应用层、业务层、基础服务层、数据层)，独立进行开发、测试、部署，组成分布式系统。

优点：降低耦合 利于团队分工协作 快速迭代 提高效率 独立部署 扩展能力强

缺点：规模大小难以界定 增加系统复杂度(通信调用、协调多个架构) 多次部署 单元测试容易整体系统测试困难  分区数据库架构难题（单个库只需访问表、分布式需要通过不同接口更新多个模块数据）

#### 此外，需要注意微服务之间的通信方式
1. 同步调用 (RESTAPI、RPC)
REST：REST基于HTTP，实现更容易，各种语言都支持，同时能够跨客户端，对客户端没有特殊的要求，只要具备HTTP的网络请求库功能就能使用。

RPC：rpc的特点是传输效率高，安全性可控，在系统内部调用实现时使用的较多。

基于REST和RPC的特点，我们通常采用的原则为：向系统外部暴露采用REST，向系统内部暴露调用采用RPC方式。

2. 异步调用（定时任务）kafaka rabbitmq
可以提高服务性能，代价是降低实时性，但数据一致性会有延时，不会立刻同步完成，但是最终会完成数据同步。

####  如何实现众多微服务

如何让分布式系统的微服务相互感知对方并进行通信（服务中心）
通过服务中心实现服务发现、服务注册、服务订阅
etcd https://zhuanlan.zhihu.com/p/143564728


### 分布式锁 https://zhuanlan.zhihu.com/p/42056183 todo
Redis分布式锁
Redis分布式锁如何实现的
分布式锁还有哪些实现方案


## 0207 golang

### 值传递 引用传递 slice forrange append 

#### 值传递 引用传递
Go 的函数参数传递都是值传递。

所谓值传递：指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。参数传递还有引用传递，

所谓引用传递是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数

因为 Go 里面的 map，slice，chan 是引用类型。变量区分值类型和引用类型。所谓值类型：变量和变量的值存在同一个位置。所谓引用类型：变量和变量的值是不同的位置，变量的值存储的是对值的引用。但并不是 map，slice，chan 的所有的变量在函数内都能被修改，不同数据类型的底层存储结构和实现可能不太一样，情况也就不一样。

#### for index, val := range collection 
    b = d 
    c[a] = d
每次循环 := 生成一个短引用对象 index, val 下标和值，作用范围只存在该次循环中 
val 短引用对原来的值拷贝后的值传递 对其进行修改不会影响到原来集合中的值

#### slice append http://c.biancheng.net/view/28.html
slice {
    cap 
    len 
    ptr 指向引用的底层数组的地址位置
}

append 容量 地址 拷贝
1. len < cap len++ 将新元素放入空余空间
2. len == cap 扩容两倍 cap*2

往一个切片中不断添加元素的过程，类似于**公司搬家**，公司发展初期，资金紧张，人员很少，所以只需要很小的房间即可容纳所有的员工，随着业务的拓展和收入的增加就需要扩充工位，但是办公地的大小是固定的，无法改变，因此公司只能选择搬家，每次搬家就需要将所有的人员转移到新的办公点。
1. 员工和工位就是切片中的元素。
2. 办公地就是分配好的内存。
3. 搬家就是重新分配内存。
4. 无论搬多少次家，公司名称始终不会变，代表外部使用切片的变量名不会修改。
5. 由于搬家后地址发生变化，因此内存“地址”也会有修改。


#### 内存管理 内存分配 内存泄漏
https://zhuanlan.zhihu.com/p/76802887

page span threadcache centralcache pageheap 

1. 使用缓存提高效率。在存储的整个体系中到处可见缓存的思想，Go内存分配和管理也使用了缓存，利用缓存一是减少了系统调用的次数，二是降低了锁的粒度、减少加锁的次数，从这2点提高了内存管理效率。

2. 以空间换时间，提高内存管理效率。空间换时间是一种常用的性能优化思想，这种思想其实非常普遍，比如Hash、Map、二叉排序树等数据结构的本质就是空间换时间，在数据库中也很常见，比如数据库索引、索引视图和数据缓存等，再如Redis等缓存数据库也是空间换时间的思想。

#### 字符串 常量 todo


### 海量数据 todo https://www.cnblogs.com/GarrettWale/p/14478347.html



## 0209

### git merge rebase  

merge 可以体现出两个分支里的commit时间线，但合并解决冲突后会产生新的commit记录，而且保留许多冗余的commit，造成git的分支树越来越复杂。

rebase 是打乱commit的时间线的，更像是移植的方法，以两条分支的公共节点为基地，将一条分支新产生的commit 移植到 当前分支上，冲突的解决直接包含在最新的commit里，不产生新的commit

feature :  a -> b -> e -> f

master : a -> b -> c -> d -> g
                                ---> e -> f  ------>
							   --->	   			     g			
merge:   两条分支呈树形的合并 a -> b -> c -> d -> e ->     产生一个用于记录合并的commit g

rebase:  master rebase feature: a -> b -> c -> d -> g -> e -> f' 从两个分支的父分支开始
